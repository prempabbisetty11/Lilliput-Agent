# Lilliput Agent ğŸ¤–

A lightweight, voice-enabled AI chat application built with **FastAPI** on the backend and a **modern glass-style web UI** on the frontend.  
The app supports **text chat**, **voice input**, and **spoken responses**, and is designed to work well on **desktop and mobile**.

---

## âœ¨ Features

- ğŸ’¬ Real-time chat with an AI model (via Groq through `litellm`)
- ğŸ¤ Voice input using browser Speech Recognition
- ğŸ”Š Natural-sounding voice output using Speech Synthesis (auto-selects best available voice)
- ğŸ“± Responsive UI (mobile, tablet, desktop)
- ğŸªŸ Liquid glass / dark UI design
- â³ Typing indicator, message timestamps, smooth animations
- ğŸ” API key handled via environment variables (no secrets in code)
- ğŸš€ Ready for cloud deployment (e.g., Render)

- ğŸ’¾ Persistent chat history (saved locally in the browser)
- ğŸŒ— Light / Dark theme toggle with smooth transitions
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Message bubble avatars (user & agent)
- âœ¨ Shimmer "typingâ€¦" indicator and subtle message animations

---

## ğŸ§± Project Structure

```
ADK_SERIES/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py            # FastAPI backend exposing /chat API
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html        # Web UI
â”‚   â”œâ”€â”€ style.css         # UI styles (dark glass theme, responsive)
â”‚   â””â”€â”€ script.js         # Frontend logic (chat, voice in/out)
â”œâ”€â”€ google_agent/
â”‚   â””â”€â”€ agent.py          # ADK agent (for CLI / experiments)
â””â”€â”€ README.md             # This file
```

---

## ğŸ§  How It Works

1. The **frontend** (HTML/CSS/JS) provides a chat interface.
2. User sends a message (text or voice).
3. The frontend calls the backend endpoint: `POST /chat`.
4. The **FastAPI backend** uses `litellm` to call the AI model via **Groq**.
5. The response is sent back to the frontend.
6. The UI displays the message and optionally speaks it aloud.

7. The UI persists messages in the browser (localStorage) so chat history is restored on refresh.
8. Users can toggle Light/Dark themes; the UI applies smooth transitions and glass effects in both modes.

---

## ğŸ› ï¸ Tech Stack & Packages

### Backend
- **Python 3**
- **FastAPI** â€“ API framework
- **Uvicorn** â€“ ASGI server
- **litellm** â€“ Unified interface to call LLM providers (Groq used here)
- **python-dotenv** (optional) â€“ For loading environment variables

### Frontend
- **HTML, CSS, JavaScript**
- Browser **SpeechRecognition** (voice input)
- Browser **SpeechSynthesis** (voice output)

### AI / API
- **Groq API** (used via `litellm`)
- Model example: `groq/llama-3.1-8b-instant` (can be changed)

---

## ğŸ”‘ API Key Configuration

This project uses a **Groq API key**.

âš ï¸ **Do NOT hardcode your API key in the code or commit it to GitHub.**

Set it as an environment variable:

### macOS / Linux:
```bash
export GROQ_API_KEY="your_groq_api_key_here"
```

### Windows (PowerShell):
```powershell
setx GROQ_API_KEY "your_groq_api_key_here"
```

Then start the backend:

```bash
uvicorn app:app --reload --app-dir backend
```

The backend will automatically read `GROQ_API_KEY` from the environment.

---

## â–¶ï¸ How to Run Locally

1. Install dependencies:
```bash
pip install fastapi uvicorn litellm python-dotenv
```

2. Set your API key (see above).

3. Start backend:
```bash
uvicorn app:app --reload --app-dir backend
```

4. Open the frontend:
- Open `frontend/index.html` in your browser.

5. Start chatting ğŸ‰

---

## ğŸŒ Deployment

This project is designed to be deployed on platforms like **Render**, **Railway**, or **Cloud Run**.

This project uses **two separate services**:
- ğŸŒ **Frontend (UI)** is hosted on **Netlify**
- ğŸ¤– **Backend (API)** is hosted on **Render**

The frontend calls the backend API endpoint on Render; this split keeps the UI always online while the API handles AI requests.

Typical steps:
- Add a `requirements.txt`
- Set `GROQ_API_KEY` in the platformâ€™s environment variables
- Start command:
```bash
uvicorn app:app --host 0.0.0.0 --port 10000 --app-dir backend
```

In production, the frontend should call the same origin (e.g., using `window.location.origin`).

The chat history feature is stored in the user's browser (localStorage). This means history persists across reloads on the same device, but not across different devices unless a backend database is added.

---

## ğŸ“š Sources & References

- Official documentation of:
  - FastAPI
  - Uvicorn
  - litellm
  - Groq API
- General web standards:
  - Web Speech API (SpeechRecognition, SpeechSynthesis)
- Design and implementation assisted by AI tools (used as a productivity aid).

---

## ğŸ¤ Notes

- This project was built as a **learning + project showcase**.
- AI tools were used in a **supporting role** (design ideas, debugging help, and code refinement), but the project structure and integration were done manually.
- API keys are **never** stored in the repository.

---

## ğŸ“„ License

This project is for educational and demonstration purposes.
You may modify and extend it for your own use.